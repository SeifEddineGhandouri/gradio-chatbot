{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276bf815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7860): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassi\\AppData\\Local\\Temp\\ipykernel_24144\\1407724081.py:207: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Enhanced Groq + Gemini Chatbot with Modern UI using Gradio\n",
    "Supports PDF, Word, Text, CSV, JSON, and Image files (Arabic OCR + scanned PDFs)\n",
    "Author: AI Assistant\n",
    "Version: 6.2\n",
    "\"\"\"\n",
    "\n",
    "import gradio as gr \n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import PyPDF2\n",
    "    PDF_SUPPORT = True\n",
    "except ImportError:\n",
    "    PDF_SUPPORT = False\n",
    "\n",
    "try:\n",
    "    import docx\n",
    "    DOCX_SUPPORT = True\n",
    "except ImportError:\n",
    "    DOCX_SUPPORT = False\n",
    "\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "    PDF2IMG_SUPPORT = True\n",
    "except ImportError:\n",
    "    PDF2IMG_SUPPORT = False\n",
    "\n",
    "GROQ_MODELS = [\n",
    "    \"llama-3.1-8b-instant\",\n",
    "    \"llama-3.1-70b-versatile\",\n",
    "    \"llama-3.3-70b-versatile\",\n",
    "    \"mixtral-8x7b-32768\",\n",
    "    \"gemma2-9b-it\",\n",
    "    \"llama3-groq-70b-8192-tool-use-preview\",\n",
    "    \"llama3-groq-8b-8192-tool-use-preview\",\n",
    "    \"gemini-pro\"\n",
    "]\n",
    "\n",
    "uploaded_file_content = \"\"\n",
    "uploaded_file_name = \"\"\n",
    "file_type = \"\"\n",
    "retriever = None\n",
    "\n",
    "custom_css = \"\"\"...\"\"\"  # Your existing CSS here\n",
    "\n",
    "class FileProcessor:\n",
    "    @staticmethod\n",
    "    def extract_ocr_df(img):\n",
    "        data = pytesseract.image_to_data(img, lang='ara', config='--psm 6', output_type=pytesseract.Output.DATAFRAME)\n",
    "        data = data.dropna().query(\"text != ''\").reset_index(drop=True)\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def regrouper_lignes_par_y(df, seuil=15):\n",
    "        lignes = []\n",
    "        ligne_courante = []\n",
    "        y_ref = None\n",
    "\n",
    "        for _, mot in df.sort_values(by=\"top\").iterrows():\n",
    "            if y_ref is None or abs(mot[\"top\"] - y_ref) <= seuil:\n",
    "                ligne_courante.append(mot[\"text\"])\n",
    "            else:\n",
    "                lignes.append(ligne_courante)\n",
    "                ligne_courante = [mot[\"text\"]]\n",
    "            y_ref = mot[\"top\"]\n",
    "\n",
    "        if ligne_courante:\n",
    "            lignes.append(ligne_courante)\n",
    "\n",
    "        return lignes\n",
    "\n",
    "    @staticmethod\n",
    "    def lignes_en_json(lignes, colonnes):\n",
    "        tableau = []\n",
    "        for ligne in lignes:\n",
    "            if len(ligne) >= len(colonnes):\n",
    "                obj = {k: ligne[i] for i, k in enumerate(colonnes)}\n",
    "                tableau.append(obj)\n",
    "        return tableau\n",
    "\n",
    "    @staticmethod\n",
    "    def analyse_pdf(pdf_path):\n",
    "        if not PDF2IMG_SUPPORT:\n",
    "            return {\"error\": \"pdf2image is not installed\"}\n",
    "\n",
    "        pages = convert_from_path(pdf_path, dpi=300)\n",
    "        textes = []\n",
    "        tableaux1 = []\n",
    "        tableaux2 = []\n",
    "\n",
    "        for i, img in enumerate(pages):\n",
    "            df = FileProcessor.extract_ocr_df(img)\n",
    "            lignes = FileProcessor.regrouper_lignes_par_y(df)\n",
    "\n",
    "            if i == 0:\n",
    "                text = \" \".join([\" \".join(l) for l in lignes])\n",
    "                textes.append(text)\n",
    "\n",
    "                idx_start = next((idx for idx, l in enumerate(lignes) if \"ÿ≥ŸàŸäÿ©\" in \" \".join(l)), None)\n",
    "                if idx_start is not None:\n",
    "                    tableaux1 = FileProcessor.lignes_en_json(lignes[idx_start+1:idx_start+6], [\n",
    "                        \"ÿπÿØÿØ ÿßŸÑÿ±ÿ™ÿ®Ÿä ŸÑŸÑŸÖÿßŸÑŸÉ\", \"ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑŸÖŸÑŸÉŸäÿ©\", \"ŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑÿ™ÿ±ÿ≥ŸäŸÖ\", \"ÿπÿØÿØ ÿßŸÑÿ≥ŸÜÿØ ÿßŸÑŸÖÿ≥ŸÑŸÖ\"\n",
    "                    ])\n",
    "\n",
    "            if i == 1:\n",
    "                idx_start = next((idx for idx, l in enumerate(lignes) if \"ÿßŸÑÿ™ÿ≠ŸÖŸÑÿßÿ™\" in \" \".join(l)), None)\n",
    "                if idx_start is not None:\n",
    "                    tableaux2 = FileProcessor.lignes_en_json(lignes[idx_start+1:idx_start+6], [\n",
    "                        \"ŸáŸàŸäÿ© ÿßŸÑŸÖÿ≥ÿ™ŸÅŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ÿ≠ŸÖŸÑÿßÿ™\", \"ŸÜŸàÿπ ÿßŸÑÿ™ÿ≠ŸÖŸÑ\", \"ÿßŸÑÿ≠ŸÇ ÿßŸÑŸÖŸàÿ∏ŸÅ ÿπŸÑŸäŸá ÿßŸÑÿ™ÿ≠ŸÖŸÑ\", \n",
    "                        \"ÿßŸÑŸÇŸäŸÖÿ© ÿ®ÿßŸÑÿØŸäŸÜÿßÿ±\", \"ÿßŸÑŸÅÿßÿ¶ÿ∂ (%)\", \"ŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑÿ™ÿ±ÿ≥ŸäŸÖ\"\n",
    "                    ])\n",
    "\n",
    "        return {\n",
    "            \"generalInformationText\": \" \".join(textes),\n",
    "            \"ÿ≥ŸàŸäÿ© ÿßŸÑŸÖÿßŸÑŸÉŸäŸÜ\": tableaux1,\n",
    "            \"ÿßŸÑÿ™ÿ≠ŸÖŸÑÿßÿ™\": tableaux2\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def read_text_file(path):\n",
    "        for enc in ['utf-8', 'utf-16', 'latin1', 'cp1252']:\n",
    "            try:\n",
    "                with open(path, 'r', encoding=enc) as f:\n",
    "                    return f.read()\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        raise Exception(\"Failed decoding file\")\n",
    "\n",
    "    @staticmethod\n",
    "    def read_pdf_file(path):\n",
    "        if not PDF_SUPPORT:\n",
    "            return \"PDF support unavailable\"\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                reader = PyPDF2.PdfReader(f)\n",
    "                text = \"\\n\".join([p.extract_text() or \"\" for p in reader.pages])\n",
    "\n",
    "            if not text.strip() and PDF2IMG_SUPPORT:\n",
    "                pages = convert_from_path(path, poppler_path=r\"C:\\\\Release-24.08.0-0 (1)\\\\poppler-24.08.0\\\\Library\\\\bin\")\n",
    "                text = \"\"\n",
    "                for img in pages:\n",
    "                    text += pytesseract.image_to_string(img, lang='ara') + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"PDF read error: {str(e)}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def read_docx_file(path):\n",
    "        if not DOCX_SUPPORT:\n",
    "            return \"DOCX support unavailable\"\n",
    "        doc = docx.Document(path)\n",
    "        return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "\n",
    "    @staticmethod\n",
    "    def read_csv_file(path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            return \"\\n\".join([\" | \".join(row) for row in reader])\n",
    "\n",
    "    @staticmethod\n",
    "    def read_json_file(path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return json.dumps(json.load(f), indent=2, ensure_ascii=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_image_file(path):\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            text = pytesseract.image_to_string(img, lang='ara', config='--psm 6')\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"OCR error: {str(e)}\"\n",
    "\n",
    "def read_file_content(path):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    processor = FileProcessor()\n",
    "    if ext == \".txt\":\n",
    "        return processor.read_text_file(path), \"Text\"\n",
    "    elif ext == \".pdf\":\n",
    "        return processor.read_pdf_file(path), \"PDF\"\n",
    "    elif ext in [\".docx\", \".doc\"]:\n",
    "        return processor.read_docx_file(path), \"Word\"\n",
    "    elif ext == \".csv\":\n",
    "        return processor.read_csv_file(path), \"CSV\"\n",
    "    elif ext == \".json\":\n",
    "        return processor.read_json_file(path), \"JSON\"\n",
    "    elif ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "        return processor.read_image_file(path), \"Image\"\n",
    "    return processor.read_text_file(path), \"Unknown\"\n",
    "\n",
    "def prepare_rag_context(raw_text):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    docs = splitter.create_documents([raw_text])\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = Chroma.from_documents(docs, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def call_groq_api(prompt, api_key, model, temperature, rag_db=None):\n",
    "    if rag_db:\n",
    "        docs = rag_db.similarity_search(prompt, k=4)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        prompt = f\"\"\"You are an AI assistant helping analyze documents.\\n\\nCONTEXT:\\n{context}\\n\\nQUESTION:\\n{prompt}\"\"\"\n",
    "\n",
    "    if \"gemini\" in model.lower():\n",
    "        url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        data = {\n",
    "            \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n",
    "            \"generationConfig\": {\"temperature\": temperature, \"topK\": 1, \"topP\": 1, \"maxOutputTokens\": 2048}\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(f\"{url}?key={api_key}\", headers=headers, json=data, timeout=30)\n",
    "            return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        except Exception as e:\n",
    "            return f\"Gemini API Error: {str(e)}\"\n",
    "    else:\n",
    "        url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "        data = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 2048,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            return f\"Groq API Error: {str(e)}\"\n",
    "\n",
    "def handle_file_upload(file):\n",
    "    global uploaded_file_content, uploaded_file_name, file_type, retriever\n",
    "    if not file:\n",
    "        uploaded_file_content = \"\"\n",
    "        uploaded_file_name = \"\"\n",
    "        file_type = \"\"\n",
    "        retriever = None\n",
    "        return \"No file uploaded\", \"\", \"üìÑ No document loaded\"\n",
    "\n",
    "    uploaded_file_name = os.path.basename(file.name)\n",
    "    content, detected = read_file_content(file.name)\n",
    "    uploaded_file_content = content\n",
    "    file_type = detected\n",
    "    retriever = prepare_rag_context(content)\n",
    "    preview = content[:1000] + (\"\\n...\" if len(content) > 1000 else \"\")\n",
    "\n",
    "    status_message = f\"‚úÖ Successfully loaded: {uploaded_file_name}\"\n",
    "    file_info = f\"üìÑ Document loaded: {uploaded_file_name} ({file_type})\"\n",
    "\n",
    "    return status_message, preview, file_info\n",
    "\n",
    "def show_raw_ocr():\n",
    "    return uploaded_file_content or \"No OCR content available\"\n",
    "\n",
    "def groq_interface(prompt, api_key, model, temperature, use_rag):\n",
    "    if not prompt.strip():\n",
    "        return \"‚ùå Please enter a prompt.\"\n",
    "    if not api_key.strip():\n",
    "        return \"‚ùå Please enter your API key.\"\n",
    "    if use_rag and not retriever:\n",
    "        return \"‚ùå Please upload a document to use RAG retrieval.\"\n",
    "    return call_groq_api(prompt, api_key, model, temperature, retriever if use_rag else None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with gr.Blocks(css=custom_css, title=\"Groq RAG Chatbot\") as app:\n",
    "        gr.HTML(\"<h1>üöÄ Groq & Gemini RAG Chatbot</h1>\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                file_upload = gr.File(label=\"Upload Document\", file_types=[\".txt\", \".pdf\", \".docx\", \".csv\", \".json\", \".png\", \".jpg\", \".jpeg\"], type=\"filepath\")\n",
    "                file_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                preview = gr.Textbox(label=\"Document Preview\", lines=8, interactive=False)\n",
    "                api_key = gr.Textbox(label=\"API Key\", type=\"password\")\n",
    "                model = gr.Dropdown(GROQ_MODELS, value=\"llama-3.1-8b-instant\", label=\"Model\")\n",
    "                temp = gr.Slider(minimum=0, maximum=1, step=0.1, value=0.7, label=\"Temperature\")\n",
    "                use_rag = gr.Checkbox(label=\"Use RAG Retrieval\", value=True)\n",
    "\n",
    "            with gr.Column(scale=2):\n",
    "                document_info = gr.Textbox(label=\"Document Status\", value=\"üìÑ No document loaded\", interactive=False)\n",
    "                prompt = gr.Textbox(label=\"Your Question\", lines=3)\n",
    "                response = gr.Textbox(label=\"AI Response\", lines=12, interactive=False)\n",
    "                send = gr.Button(\"Send Message\")\n",
    "\n",
    "        file_upload.change(fn=handle_file_upload, inputs=[file_upload], outputs=[file_status, preview, document_info])\n",
    "        send.click(fn=groq_interface, inputs=[prompt, api_key, model, temp, use_rag], outputs=[response])\n",
    "        prompt.submit(fn=groq_interface, inputs=[prompt, api_key, model, temp, use_rag], outputs=[response])\n",
    "        show_ocr_btn = gr.Button(\"üëÅÔ∏è Show Raw OCR Text\")\n",
    "        show_ocr_btn.click(fn=show_raw_ocr, inputs=[], outputs=[response])\n",
    "\n",
    "    app.launch(server_name=\"0.0.0.0\", server_port=None, inbrowser=True, share=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
